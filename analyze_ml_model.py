#!/usr/bin/env python3
"""
An√°lisis del rendimiento actual del modelo ML
"""

import joblib
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

def analyze_current_model():
    """Analizar el rendimiento actual del modelo ML"""
    print('=== AN√ÅLISIS DEL MODELO ML ACTUAL ===')

    try:
        # Cargar modelo actual
        model_data = joblib.load('nexus_system/memory_archives/ml_model.pkl')
        scaler = joblib.load('nexus_system/memory_archives/scaler.pkl')

        if isinstance(model_data, dict):
            model = model_data.get('model')
            metadata = model_data.get('metadata', {})

            print(f'Modelo: {metadata.get("version", "desconocido")}')
            accuracy = metadata.get("accuracy")
            cv_score = metadata.get("cv_score")
            if accuracy:
                print('.1%')
            else:
                print(f'Accuracy reportado: {accuracy}')

            if cv_score:
                print('.1%')
            else:
                print(f'CV Score: {cv_score}')
            print(f'S√≠mbolos entrenados: {len(metadata.get("symbols", []))}')
            print(f'Muestras de entrenamiento: {metadata.get("total_samples", "N/A")}')

            # Verificar importancia de features
            if hasattr(model, 'feature_importances_'):
                print('\nTop 10 features m√°s importantes:')
                features = model_data.get('feature_names', [])
                importances = model.feature_importances_
                if len(features) == len(importances):
                    sorted_idx = np.argsort(importances)[::-1]
                    for i, idx in enumerate(sorted_idx[:10]):
                        print(f'{i+1:2d}. {features[idx]:25} {importances[idx]:.4f}')

            print('\n=== CLASES DEL MODELO ===')
            label_encoder = model_data.get('label_encoder')
            if label_encoder and hasattr(label_encoder, 'classes_'):
                for i, class_name in enumerate(label_encoder.classes_):
                    print(f'{i}: {class_name}')

        else:
            print('Modelo en formato legacy')

    except Exception as e:
        print(f'Error analizando modelo: {e}')
        import traceback
        traceback.print_exc()

def propose_improvements():
    """Proponer mejoras espec√≠ficas para aumentar accuracy"""
    print('\n' + '='*50)
    print('üöÄ PROPUESTAS PARA MEJORAR ACCURACY DEL MODELO ML')
    print('='*50)

    print('\n1. üìä EXPANSI√ìN DE DATASET:')
    print('   ‚Ä¢ M√°s datos hist√≥ricos (6-12 meses m√≠nimo)')
    print('   ‚Ä¢ Condiciones de mercado variadas (bull, bear, sideways)')
    print('   ‚Ä¢ Diferentes pares de trading (m√°s all√° de USDT)')
    print('   ‚Ä¢ Datos de diferentes exchanges para robustez')

    print('\n2. üõ†Ô∏è FEATURES ENGINEERING AVANZADO:')
    print('   ‚Ä¢ Sentiment Analysis (News, Social Media)')
    print('   ‚Ä¢ Order Flow & Volume Analysis')
    print('   ‚Ä¢ Inter-market correlations (BTC vs Altcoins)')
    print('   ‚Ä¢ Economic indicators (inter√©s, inflaci√≥n)')
    print('   ‚Ä¢ Features temporales avanzados')

    print('\n3. üéØ HIPERPAR√ÅMETROS OPTIMIZADOS:')
    print('   ‚Ä¢ Grid Search con validaci√≥n cruzada')
    print('   ‚Ä¢ Bayesian Optimization')
    print('   ‚Ä¢ Early stopping autom√°tico')

    print('\n4. üîÑ VALIDACI√ìN TEMPORAL:')
    print('   ‚Ä¢ TimeSeriesSplit en lugar de KFold')
    print('   ‚Ä¢ Walk-forward validation')
    print('   ‚Ä¢ Out-of-sample testing robusto')

    print('\n5. üé™ ENSEMBLE METHODS:')
    print('   ‚Ä¢ Random Forest + XGBoost + LightGBM')
    print('   ‚Ä¢ Voting Classifier')
    print('   ‚Ä¢ Stacking con meta-learner')

    print('\n6. üìà FEATURE SELECTION:')
    print('   ‚Ä¢ Recursive Feature Elimination (RFE)')
    print('   ‚Ä¢ Feature importance analysis')
    print('   ‚Ä¢ Correlation-based selection')

    print('\n7. üé® DATA AUGMENTATION:')
    print('   ‚Ä¢ Synthetic data generation')
    print('   ‚Ä¢ Noise injection')
    print('   ‚Ä¢ Time series augmentation')

if __name__ == "__main__":
    analyze_current_model()
    propose_improvements()
