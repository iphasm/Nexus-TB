#!/usr/bin/env python3
"""
Script de prueba para verificar la integraci√≥n completa de OpenAI GPT-4o en Nexus Core.
"""

import os
import sys
import asyncio
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

def test_openai_configuration():
    """Prueba la configuraci√≥n b√°sica de OpenAI."""
    print("üîß PRUEBA DE CONFIGURACI√ìN OPENAI")
    print("=" * 50)

    # Usar API key desde variable de entorno (NO HARDCODEAR)
    api_key = os.getenv("OPENAI_API_KEY", "").strip("'\" ")
    if not api_key:
        print("‚ùå OPENAI_API_KEY no encontrada en variables de entorno")
        print("   Configura: export OPENAI_API_KEY='tu_api_key_aqui'")
        return False

    try:
        import openai
        client = openai.OpenAI(api_key=api_key)

        # Verificar modelos disponibles
        models = client.models.list()
        available_models = [model.id for model in models.data]

        print("‚úÖ API Key: V√°lida")
        print(f"üìä Modelos disponibles: {len(available_models)}")

        # Verificar GPT-4o
        if "gpt-4o" in available_models:
            print("‚úÖ GPT-4o: Disponible")
        else:
            print("‚ùå GPT-4o: NO disponible")
            return False

        # Verificar GPT-4o-mini
        if "gpt-4o-mini" in available_models:
            print("‚úÖ GPT-4o-mini: Disponible")
        else:
            print("‚ö†Ô∏è GPT-4o-mini: NO disponible")

        return True

    except Exception as e:
        print(f"‚ùå Error de configuraci√≥n: {e}")
        return False

async def test_nexus_analyst():
    """Prueba el NexusAnalyst con GPT-4o."""
    print("\nü§ñ PRUEBA DE NEXUS ANALYST")
    print("=" * 50)

    try:
        from servos.ai_analyst import NexusAnalyst

        analyst = NexusAnalyst()
        if not analyst.client:
            print("‚ùå NexusAnalyst: Cliente no inicializado")
            return False

        print(f"‚úÖ NexusAnalyst inicializado con modelo: {analyst.model}")

        # Prueba b√°sica de conectividad
        test_response = await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: analyst.client.chat.completions.create(
                model=analyst.model,
                messages=[{"role": "user", "content": "Hola, responde con una sola palabra: OK"}],
                max_tokens=10
            )
        )

        response_text = test_response.choices[0].message.content.strip()
        print(f"‚úÖ Respuesta de prueba: '{response_text}'")

        # Verificar que us√≥ GPT-4o
        if "gpt-4o" in str(test_response.model):
            print("‚úÖ Modelo correcto usado en la respuesta")
        else:
            print(f"‚ö†Ô∏è Modelo diferente usado: {test_response.model}")

        return True

    except Exception as e:
        print(f"‚ùå Error en NexusAnalyst: {e}")
        return False

async def test_task_scheduler():
    """Prueba el TaskScheduler con GPT-4o."""
    print("\nüìÖ PRUEBA DE TASK SCHEDULER")
    print("=" * 50)

    try:
        from servos.task_scheduler import TaskScheduler

        scheduler = TaskScheduler()
        if not scheduler.client:
            print("‚ùå TaskScheduler: Cliente no inicializado")
            return False

        print(f"‚úÖ TaskScheduler inicializado con modelo: {scheduler.model}")

        # Prueba b√°sica de parsing
        test_prompt = "Recu√©rdame comprar caf√© ma√±ana a las 9 AM"

        # Simular parsing (sin ejecutar el scheduling completo)
        try:
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: scheduler.client.chat.completions.create(
                    model=scheduler.model,
                    messages=[
                        {"role": "system", "content": "Parse scheduling requests into JSON format."},
                        {"role": "user", "content": test_prompt}
                    ],
                    max_tokens=50
                )
            )

            print(f"‚úÖ TaskScheduler parsing funciona: {len(response.choices[0].message.content)} caracteres")

            if "gpt-4o" in str(response.model):
                print("‚úÖ TaskScheduler usa modelo correcto")
            else:
                print(f"‚ö†Ô∏è TaskScheduler usa modelo diferente: {response.model}")

        except Exception as e:
            print(f"‚ö†Ô∏è TaskScheduler parsing fall√≥: {e}")
            # No es cr√≠tico para la prueba b√°sica

        return True

    except Exception as e:
        print(f"‚ùå Error en TaskScheduler: {e}")
        return False

def test_system_directive():
    """Prueba la configuraci√≥n en system_directive.py."""
    print("\n‚öôÔ∏è PRUEBA DE SYSTEM DIRECTIVE")
    print("=" * 50)

    try:
        from system_directive import OPENAI_MODEL
        print(f"‚úÖ OPENAI_MODEL configurado: {OPENAI_MODEL}")

        if OPENAI_MODEL == "gpt-4o":
            print("‚úÖ Modelo correcto configurado (GPT-4o)")
            return True
        else:
            print(f"‚ö†Ô∏è Modelo diferente configurado: {OPENAI_MODEL}")
            return False

    except ImportError:
        print("‚ùå No se puede importar OPENAI_MODEL desde system_directive")
        return False
    except Exception as e:
        print(f"‚ùå Error en system_directive: {e}")
        return False

async def run_comprehensive_test():
    """Ejecuta todas las pruebas."""
    print("üöÄ INICIANDO PRUEBAS COMPRENSIVAS DE OPENAI INTEGRATION")
    print("=" * 60)

    results = []

    # 1. Configuraci√≥n b√°sica
    results.append(("Configuraci√≥n OpenAI", test_openai_configuration()))

    # 2. System directive
    results.append(("System Directive", test_system_directive()))

    # 3. Nexus Analyst
    results.append(("Nexus Analyst", await test_nexus_analyst()))

    # 4. Task Scheduler
    results.append(("Task Scheduler", await test_task_scheduler()))

    # Resultados finales
    print("\n" + "=" * 60)
    print("üìä RESULTADOS FINALES")
    print("=" * 60)

    all_passed = True
    for test_name, passed in results:
        status = "‚úÖ PAS√ì" if passed else "‚ùå FALL√ì"
        print(f"{test_name}: {status}")
        if not passed:
            all_passed = False

    print("\n" + "=" * 60)
    if all_passed:
        print("üéâ ¬°TODAS LAS PRUEBAS PASARON! OpenAI GPT-4o est√° correctamente configurado.")
        print("\nüí° El Nexus Core ahora puede usar GPT-4o para:")
        print("   ‚Ä¢ An√°lisis de se√±ales con personalidad")
        print("   ‚Ä¢ An√°lisis de sentimiento de mercado")
        print("   ‚Ä¢ Programaci√≥n inteligente de tareas")
        print("   ‚Ä¢ An√°lisis macro y FOMC")
        print("   ‚Ä¢ Generaci√≥n de briefings de mercado")
    else:
        print("‚ö†Ô∏è Algunas pruebas fallaron. Revisa la configuraci√≥n.")

    return all_passed

if __name__ == "__main__":
    try:
        # Verificar que la API key est√© configurada
        if not os.getenv("OPENAI_API_KEY"):
            print("‚ùå OPENAI_API_KEY no configurada")
            print("   Ejecuta: export OPENAI_API_KEY='tu_api_key_aqui'")
            print("   Luego: python test_openai_integration.py")
            sys.exit(1)

        # Ejecutar pruebas
        asyncio.run(run_comprehensive_test())

    except Exception as e:
        print(f"‚ùå Error cr√≠tico ejecutando pruebas: {e}")
        sys.exit(1)
